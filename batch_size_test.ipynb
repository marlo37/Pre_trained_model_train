{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM3Ayz/D7QUaDOKPjM8RdAq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marlo37/Pre_trained_model_train/blob/main/batch_size_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "upQfv1Zgb12q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ed4635-a9f9-4a39-e3ce-aeca64c3adeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!nvcc -V\n",
        "!pip3 install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aokv9PUWekL"
      },
      "source": [
        "Source: https://github.com/dandiws/CNN-MNIST-pytorch/blob/master/cnn_mnist.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "def main(batch_size):\n",
        "    torch.manual_seed(2)\n",
        "    torch.cuda.manual_seed_all(2)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    def im_convert(tensor):\n",
        "        image = tensor.to(\"cpu\").clone().detach()\n",
        "        image = image.numpy().squeeze()\n",
        "        return image\n",
        "\n",
        "    class Net(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(Net,self).__init__()\n",
        "            self.conv1 = nn.Conv2d(1,10,kernel_size=5,stride=1)\n",
        "            self.conv2 = nn.Conv2d(10,10,kernel_size=5,stride=1)\n",
        "            self.pool = nn.MaxPool2d(kernel_size=2,stride=2) #2x2 maxpool\n",
        "            self.fc1 = nn.Linear(4*4*10,100)\n",
        "            self.fc2 = nn.Linear(100,10)\n",
        "\n",
        "        def forward(self,x):\n",
        "            x = F.relu(self.conv1(x)) #24x24x10\n",
        "            x = self.pool(x) #12x12x10\n",
        "            x = F.relu(self.conv2(x)) #8x8x10\n",
        "            x = self.pool(x) #4x4x10\n",
        "            x = x.view(-1, 4*4*10) #flattening\n",
        "            x = F.relu(self.fc1(x))\n",
        "            x = self.fc2(x)\n",
        "            return x\n",
        "\n",
        "    train_ds = datasets.MNIST('../data',train=True,download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "    validation_split = .1\n",
        "    shuffle_dataset = True\n",
        "    random_seed= 2\n",
        "\n",
        "    # Creating data indices for training and validation splits:\n",
        "    dataset_size = len(train_ds)\n",
        "    indices = list(range(dataset_size))\n",
        "    split = int(np.floor(validation_split * dataset_size))\n",
        "    if shuffle_dataset :\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "    train_indices, val_indices = indices[split:], indices[:split]\n",
        "    # Creating PT data samplers and loaders:\n",
        "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "    valid_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
        "\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size,\n",
        "                                            sampler=train_sampler)\n",
        "    validation_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size,\n",
        "                                                    sampler=valid_sampler)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data',train=False,download=True,\n",
        "        transform=transforms.Compose([transforms.ToTensor()])),batch_size=batch_size,shuffle=True)\n",
        "\n",
        "    # fig, ax = plt.subplots(nrows=2,ncols=3)\n",
        "\n",
        "    # i=0\n",
        "    # for row in ax:\n",
        "    #   for col in row:\n",
        "    #     col.imshow(im_convert(train_loader.dataset[i][0]))\n",
        "    #     col.set_title(\"digit \"+str(train_loader.dataset[i][1]))\n",
        "    #     col.axis(\"off\")\n",
        "    #     i+=1\n",
        "\n",
        "    model = Net().cuda()\n",
        "    optimizer = optim.SGD(model.parameters(),lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_errors = []\n",
        "    train_acc = []\n",
        "    val_errors = []\n",
        "    val_acc = []\n",
        "    n_train = len(train_loader)*batch_size\n",
        "    n_val = len(validation_loader)*batch_size\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "    for i in range(10):\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        c = 0\n",
        "        for images,labels in train_loader:\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(images)\n",
        "            loss = criterion(output,labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss+=loss.item()\n",
        "            total_acc+=torch.sum(torch.max(output,dim=1)[1]==labels).item()*1.0\n",
        "            c+=1\n",
        "\n",
        "\n",
        "        #validation\n",
        "\n",
        "        total_loss_val = 0\n",
        "        total_acc_val = 0\n",
        "        c = 0\n",
        "        for images,labels in validation_loader:\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "            output = model(images)\n",
        "            loss = criterion(output,labels)\n",
        "\n",
        "            total_loss_val +=loss.item()\n",
        "            total_acc_val +=torch.sum(torch.max(output,dim=1)[1]==labels).item()*1.0\n",
        "            c+=1\n",
        "\n",
        "        train_errors.append(total_loss/n_train)\n",
        "        train_acc.append(total_acc/n_train)\n",
        "        val_errors.append(total_loss_val/n_val)\n",
        "        val_acc.append(total_acc_val/n_val)\n",
        "    end_time = time.time()-start_time\n",
        "\n",
        "    \"\"\"\n",
        "    print(\"Trainig complete\")\n",
        "\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2)\n",
        "    ax[0].plot(train_errors, 'r',label=\"Train\")\n",
        "    ax[0].plot(val_errors, 'g', label=\"Validation\")\n",
        "    ax[0].set_title(\"Grafik error\")\n",
        "    ax[0].set_ylabel(\"Error (cross-entropy)\")\n",
        "    ax[0].set_xlabel(\"Epoch\")\n",
        "    ax[0].legend()\n",
        "    ax[1].plot(train_acc, 'r',label=\"Train\")\n",
        "    ax[1].plot(val_acc, 'g', label=\"Validation\")\n",
        "    ax[1].set_title(\"Grafik akurasi\")\n",
        "    ax[1].set_ylabel(\"Accuracy\")\n",
        "    ax[1].set_xlabel(\"Epoch\")\n",
        "    ax[1].legend()\n",
        "    plt.show()\n",
        "    \"\"\"\n",
        "\n",
        "    total_acc = 0\n",
        "    for images,labels in test_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        output = model(images)\n",
        "        total_acc+=torch.sum(torch.max(output,dim=1)[1]==labels).item()*1.0\n",
        "\n",
        "    print(f\"Batch size {batch_size} Time required {end_time}s :\",total_acc/len(test_loader.dataset))"
      ],
      "metadata": {
        "id": "YvnCoLYqcjRu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(256)\n",
        "main(128)\n",
        "main(64)\n",
        "main(32)\n",
        "main(16)\n",
        "main(8)\n",
        "main(4)\n",
        "main(2)\n",
        "main(1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTouIPDccot2",
        "outputId": "3cb377c8-ecdf-4e7b-c30d-ffaa18ab2cad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 277964533.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 39342544.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 234604002.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4542/4542 [00:00<00:00, 6326977.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Batch size 256 Time required 66.33616018295288s : 0.9414\n",
            "Batch size 128 Time required 70.93315362930298s : 0.9669\n",
            "Batch size 64 Time required 79.03622579574585s : 0.978\n",
            "Batch size 32 Time required 95.71692824363708s : 0.9848\n",
            "Batch size 16 Time required 144.3849356174469s : 0.9858\n",
            "Batch size 8 Time required 199.46242308616638s : 0.9845\n",
            "Batch size 4 Time required 329.23670983314514s : 0.9846\n",
            "Batch size 2 Time required 590.1485893726349s : 0.9878\n",
            "Batch size 1 Time required 1100.3400127887726s : 0.9717\n"
          ]
        }
      ]
    }
  ]
}